{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brinaseidel/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>date_x</th>\n",
       "      <th>time</th>\n",
       "      <th>loc_t ype</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>council_district</th>\n",
       "      <th>apd_sector</th>\n",
       "      <th>apd_district</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>...</th>\n",
       "      <th>P0030006_pct</th>\n",
       "      <th>P0030007_pct</th>\n",
       "      <th>P0030008_pct</th>\n",
       "      <th>P0040003_pct</th>\n",
       "      <th>P0200002_pct</th>\n",
       "      <th>P0250002_pct</th>\n",
       "      <th>P0190007_pct</th>\n",
       "      <th>B19113_001E</th>\n",
       "      <th>B17001_001E_pct</th>\n",
       "      <th>C18120_003E_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-01 20:19:00</td>\n",
       "      <td>10/01/2014</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>RESIDENCE / HOME</td>\n",
       "      <td>78723.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>30.315506</td>\n",
       "      <td>-97.690678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.211769</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>0.529424</td>\n",
       "      <td>0.402545</td>\n",
       "      <td>0.130133</td>\n",
       "      <td>0.337189</td>\n",
       "      <td>35600.0</td>\n",
       "      <td>0.994701</td>\n",
       "      <td>0.88417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-10-05 16:33:00</td>\n",
       "      <td>10/05/2014</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>RESIDENCE / HOME</td>\n",
       "      <td>78723.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>30.315506</td>\n",
       "      <td>-97.690678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.211769</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>0.529424</td>\n",
       "      <td>0.402545</td>\n",
       "      <td>0.130133</td>\n",
       "      <td>0.337189</td>\n",
       "      <td>35600.0</td>\n",
       "      <td>0.994701</td>\n",
       "      <td>0.88417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-20 22:30:00</td>\n",
       "      <td>01/20/2012</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>PARKING LOTS / GARAGE</td>\n",
       "      <td>78723.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>30.320667</td>\n",
       "      <td>-97.687671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.211769</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>0.529424</td>\n",
       "      <td>0.402545</td>\n",
       "      <td>0.130133</td>\n",
       "      <td>0.337189</td>\n",
       "      <td>35600.0</td>\n",
       "      <td>0.994701</td>\n",
       "      <td>0.88417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 20:00:00</td>\n",
       "      <td>01/01/2011</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RESIDENCE / HOME</td>\n",
       "      <td>78723.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>30.320667</td>\n",
       "      <td>-97.687671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.211769</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>0.529424</td>\n",
       "      <td>0.402545</td>\n",
       "      <td>0.130133</td>\n",
       "      <td>0.337189</td>\n",
       "      <td>35600.0</td>\n",
       "      <td>0.994701</td>\n",
       "      <td>0.88417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-03-06 05:00:00</td>\n",
       "      <td>03/06/2012</td>\n",
       "      <td>500.0</td>\n",
       "      <td>RESIDENCE / HOME</td>\n",
       "      <td>78723.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>30.320667</td>\n",
       "      <td>-97.687671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.211769</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>0.529424</td>\n",
       "      <td>0.402545</td>\n",
       "      <td>0.130133</td>\n",
       "      <td>0.337189</td>\n",
       "      <td>35600.0</td>\n",
       "      <td>0.994701</td>\n",
       "      <td>0.88417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time      date_x    time              loc_t ype  zip_code  \\\n",
       "0  2014-10-01 20:19:00  10/01/2014  2019.0       RESIDENCE / HOME   78723.0   \n",
       "1  2014-10-05 16:33:00  10/05/2014  1633.0       RESIDENCE / HOME   78723.0   \n",
       "2  2012-01-20 22:30:00  01/20/2012  2230.0  PARKING LOTS / GARAGE   78723.0   \n",
       "3  2011-01-01 20:00:00  01/01/2011  2000.0       RESIDENCE / HOME   78723.0   \n",
       "4  2012-03-06 05:00:00  03/06/2012   500.0       RESIDENCE / HOME   78723.0   \n",
       "\n",
       "   council_district apd_sector apd_district   latitude  longtitude  \\\n",
       "0               1.0         ID            1  30.315506  -97.690678   \n",
       "1               1.0         ID            1  30.315506  -97.690678   \n",
       "2               1.0         ID            1  30.320667  -97.687671   \n",
       "3               1.0         ID            1  30.320667  -97.687671   \n",
       "4               1.0         ID            1  30.320667  -97.687671   \n",
       "\n",
       "        ...        P0030006_pct  P0030007_pct  P0030008_pct  P0040003_pct  \\\n",
       "0       ...              0.0004      0.211769      0.064652      0.529424   \n",
       "1       ...              0.0004      0.211769      0.064652      0.529424   \n",
       "2       ...              0.0004      0.211769      0.064652      0.529424   \n",
       "3       ...              0.0004      0.211769      0.064652      0.529424   \n",
       "4       ...              0.0004      0.211769      0.064652      0.529424   \n",
       "\n",
       "   P0200002_pct  P0250002_pct  P0190007_pct  B19113_001E  B17001_001E_pct  \\\n",
       "0      0.402545      0.130133      0.337189      35600.0         0.994701   \n",
       "1      0.402545      0.130133      0.337189      35600.0         0.994701   \n",
       "2      0.402545      0.130133      0.337189      35600.0         0.994701   \n",
       "3      0.402545      0.130133      0.337189      35600.0         0.994701   \n",
       "4      0.402545      0.130133      0.337189      35600.0         0.994701   \n",
       "\n",
       "   C18120_003E_pct  \n",
       "0          0.88417  \n",
       "1          0.88417  \n",
       "2          0.88417  \n",
       "3          0.88417  \n",
       "4          0.88417  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.read_csv(\"../Personal Response_to_Resistance/Input Data/clean_data.csv\", header=0)\n",
    "#combined = pd.read_csv('clean_data.csv')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APD sector\n",
    "apd_sector_dummies = pd.get_dummies(combined.apd_sector)\n",
    "cols = []\n",
    "for col in apd_sector_dummies.columns:\n",
    "    cols.append(\"apd_sector\"+str(col))\n",
    "apd_sector_dummies.columns = cols\n",
    "\n",
    "# Zip codes\n",
    "zip_dummies = pd.get_dummies(combined.zip_code)\n",
    "cols = []\n",
    "for col in zip_dummies.columns:\n",
    "    cols.append(\"zip\"+str(int(col)))\n",
    "zip_dummies.columns = cols\n",
    "\n",
    "combined = pd.concat([combined, apd_sector_dummies, zip_dummies], axis=1)\n",
    "\n",
    "# Location type\n",
    "loc_type_dummies = pd.get_dummies(combined['loc_t ype'])\n",
    "cols = []\n",
    "for col in loc_type_dummies.columns:\n",
    "    cols.append(\"loc_type\"+str(col))\n",
    "loc_type_dummies.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing data\n",
    "\n",
    "NOTE: Try taking out loc_type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = [\"temp_max\", \"temp_min\", \"prec_avg\", 'new_year', 'mlk_day', 'wash_bday', 'mem_day', 'ind_day', \n",
    "      'labor_day', 'col_day', 'vet_day', 'thanksgiving', 'christmas', 'P0030001','P0030002_pct', 'P0030003_pct', 'P0030004_pct', 'P0030005_pct', 'P0030006_pct', \n",
    "      'P0040003_pct', 'P0130001', 'B19113_001E', 'B17001_001E_pct', 'C18120_003E_pct']\n",
    "months = [col for col in combined if col.startswith('month') and col != \"month\"]\n",
    "days = [col for col in combined if col.startswith('day') and col != \"day_of_week\"]\n",
    "hours = [col for col in combined if col.startswith('hour') and col != \"hour_of_day\"]\n",
    "zips = [col for col in combined if col.startswith('zip') and col != \"zip_code\"]\n",
    "apd_sectors =  [col for col in combined if col.startswith('apd_sector') and col != \"apd_sector\"]\n",
    "loc_type = [col for col in combined if col.startswith('loc_type')]\n",
    "cols_to_use = cols_to_use + months + days + hours + zips + apd_sectors + loc_type\n",
    "cols_to_use_y = cols_to_use + [\"Target1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records dropped because of nans: 15634\n"
     ]
    }
   ],
   "source": [
    "combined_nonmiss = combined[cols_to_use_y].dropna()\n",
    "print('Records dropped because of nans: '+str(len(combined)-len(combined_nonmiss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_nonmiss[cols_to_use]\n",
    "y = combined_nonmiss[\"Target1\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.0    0.987127\n",
      "1.0    0.012873\n",
      "Name: Target1, dtype: float64\n",
      "\n",
      "Testing:\n",
      "0.0    0.98713\n",
      "1.0    0.01287\n",
      "Name: Target1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check that the stratification worked\n",
    "print(\"Training:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nTesting:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up stratified k fold split\n",
    "skf = StratifiedKFold(n_splits=5, random_state=400)\n",
    "skf.get_n_splits(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6056093879095984,\n",
       " 0.6270041387567771,\n",
       " 0.6215275234117839,\n",
       " 0.612473816393459,\n",
       " 0.6217097231565192]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression \n",
    "auc_lr = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    model = LogisticRegression(C=1e30).fit(X_train_fold.drop(['month1', 'hour0', 'day1', 'apd_sector1', 'zip76574'], axis=1), y_train_fold)\n",
    "    \n",
    "    y_pred_fold = model.predict_proba(X_test_fold.drop(['month1', 'hour0', 'day1', 'apd_sector1', 'zip76574'], axis=1))[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_fold, y_pred_fold)\n",
    "    auc_lr.append(auc(fpr, tpr))\n",
    "\n",
    "auc_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6894346829656525,\n",
       " 0.6920072692797773,\n",
       " 0.6976217270829276,\n",
       " 0.6879365253121915,\n",
       " 0.6937605327510444]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive bayes\n",
    "auc_nb = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    model = BernoulliNB().fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_pred_fold = model.predict_proba(X_test_fold)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_fold, y_pred_fold)\n",
    "    auc_nb.append(auc(fpr, tpr))\n",
    "\n",
    "auc_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5517940807912758,\n",
       " 0.5556195368472145,\n",
       " 0.5560494603633377,\n",
       " 0.5545349292565165,\n",
       " 0.5535502087327919]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree\n",
    "auc_dt = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    \n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    model = DecisionTreeClassifier(criterion=\"entropy\").fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_pred_fold = model.predict_proba(X_test_fold)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_fold, y_pred_fold)\n",
    "    auc_dt.append(auc(fpr, tpr))\n",
    "\n",
    "auc_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM - THIS DOESN\"T WORK (in a reasonable amount of time)!\n",
    "auc_svm = []\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "        \n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    svm_model = svm.SVC(kernel='linear')\n",
    "    svm_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_pred_fold = svm.predict_proba(X_test_fold)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_fold, y_pred_fold)\n",
    "    auc_svm.append(auc(fpr, tpr))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the vars we have (just for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'date_time', \n",
      "'date_x', \n",
      "'time', \n",
      "'loc_t ype', \n",
      "'zip_code', \n",
      "'council_district', \n",
      "'apd_sector', \n",
      "'apd_district', \n",
      "'latitude', \n",
      "'longtitude', \n",
      "'location', \n",
      "'year', \n",
      "'Target1', \n",
      "'Target2', \n",
      "'temp_max', \n",
      "'temp_avg', \n",
      "'temp_min', \n",
      "'dew_max', \n",
      "'dew_avg', \n",
      "'dew_min', \n",
      "'hum_max', \n",
      "'hum_min', \n",
      "'wind_max', \n",
      "'wind_min', \n",
      "'pres_max', \n",
      "'pres_min', \n",
      "'prec_avg', \n",
      "'new_year', \n",
      "'mlk_day', \n",
      "'wash_bday', \n",
      "'mem_day', \n",
      "'ind_day', \n",
      "'labor_day', \n",
      "'col_day', \n",
      "'vet_day', \n",
      "'thanksgiving', \n",
      "'christmas', \n",
      "'month', \n",
      "'day_of_week', \n",
      "'hour_of_day', \n",
      "'month1', \n",
      "'month2', \n",
      "'month3', \n",
      "'month4', \n",
      "'month5', \n",
      "'month6', \n",
      "'month7', \n",
      "'month8', \n",
      "'month9', \n",
      "'month10', \n",
      "'month11', \n",
      "'month12', \n",
      "'day0', \n",
      "'day1', \n",
      "'day2', \n",
      "'day3', \n",
      "'day4', \n",
      "'day5', \n",
      "'day6', \n",
      "'hour0', \n",
      "'hour1', \n",
      "'hour2', \n",
      "'hour3', \n",
      "'hour4', \n",
      "'hour5', \n",
      "'hour6', \n",
      "'hour7', \n",
      "'hour8', \n",
      "'hour9', \n",
      "'hour10', \n",
      "'hour11', \n",
      "'hour12', \n",
      "'hour13', \n",
      "'hour14', \n",
      "'hour15', \n",
      "'hour16', \n",
      "'hour17', \n",
      "'hour18', \n",
      "'hour19', \n",
      "'hour20', \n",
      "'hour21', \n",
      "'hour22', \n",
      "'hour23', \n",
      "'tract', \n",
      "'P0030001', \n",
      "'P0130001', \n",
      "'P0130002', \n",
      "'P0130003', \n",
      "'P0030002_pct', \n",
      "'P0030003_pct', \n",
      "'P0030004_pct', \n",
      "'P0030005_pct', \n",
      "'P0030006_pct', \n",
      "'P0030007_pct', \n",
      "'P0030008_pct', \n",
      "'P0040003_pct', \n",
      "'P0200002_pct', \n",
      "'P0250002_pct', \n",
      "'P0190007_pct', \n",
      "'B19113_001E', \n",
      "'B17001_001E_pct', \n",
      "'C18120_003E_pct', \n"
     ]
    }
   ],
   "source": [
    "for col in combined.columns:\n",
    "    print(\"'\"+col+\"', \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
