{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Crime Data\n",
    "\n",
    "Final project for DS1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the crime report data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brinaseidel/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (16,20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "crimes2004_2018 = pd.read_csv(\"https://data.austintexas.gov/api/views/fdj4-gpfu/rows.csv?accessType=DOWNLOAD\", dtype={'Census Tract': object})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns - columns_largeset below is the simplification of the column i.e. replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Incident Number', 'Highest Offense Description',\n",
      "       'Highest Offense Code', 'Family Violence', 'Occurred Date Time',\n",
      "       'Occurred Date', 'Occurred Time', 'Report Date Time', 'Report Date',\n",
      "       'Report Time', 'Location Type', 'Address', 'Zip Code',\n",
      "       'Council District', 'APD Sector', 'APD District', 'PRA', 'Census Tract',\n",
      "       'Clearance Status', 'Clearance Date', 'UCR Category',\n",
      "       'Category Description', 'X-coordinate', 'Y-coordinate', 'Latitude',\n",
      "       'Longitude', 'Location'],\n",
      "      dtype='object')\n",
      "['inc_number', 'high_off_desc', 'high_off_code', 'fam_viol', 'date_time', 'date', 'time', 'report_date_time', 'report_date', 'report_time', 'loc_t ype', 'address', 'zip_code', 'council_district', 'apd_sector', 'apd_district', 'pra', 'cen_tract', 'clr_status', 'clr_date', 'ucr', 'cat_desc', 'x_coord', 'y_coord', 'latitude', 'longtitude', 'location']\n"
     ]
    }
   ],
   "source": [
    "print(crimes2004_2018.columns)\n",
    "columns_largeset = ['inc_number', 'high_off_desc', 'high_off_code', 'fam_viol', 'date_time', 'date', 'time', 'report_date_time', 'report_date']\n",
    "columns2_largeset = ['report_time', 'loc_t ype', 'address', 'zip_code', 'council_district', 'apd_sector', 'apd_district', 'pra', 'cen_tract', 'clr_status', 'clr_date', 'ucr', 'cat_desc', 'x_coord', 'y_coord', 'latitude', 'longtitude', 'location']\n",
    "columns_largeset += columns2_largeset\n",
    "print(columns_largeset)\n",
    "crimes2004_2018.columns = columns_largeset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have resistence data for 2009 to 2016, so we will keep only the corresponding years of crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(crimes2004_2018['inc_number'].astype(str))\n",
    "temp = [l[0:4] for l  in temp]\n",
    "crimes2004_2018['year']= np.array(temp)\n",
    "crimes2009_2016 = crimes2004_2018.loc[crimes2004_2018['year'].isin(['2009','2010', '2011', '2012', '2013', '2014', '2015', '2016'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049923, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inc_number</th>\n",
       "      <th>high_off_desc</th>\n",
       "      <th>high_off_code</th>\n",
       "      <th>fam_viol</th>\n",
       "      <th>date_time</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>report_date_time</th>\n",
       "      <th>report_date</th>\n",
       "      <th>report_time</th>\n",
       "      <th>...</th>\n",
       "      <th>clr_status</th>\n",
       "      <th>clr_date</th>\n",
       "      <th>ucr</th>\n",
       "      <th>cat_desc</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longtitude</th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20145043640</td>\n",
       "      <td>VIOL OF PROTECTIVE ORDER</td>\n",
       "      <td>3009</td>\n",
       "      <td>N</td>\n",
       "      <td>10/01/2014 08:19:00 PM</td>\n",
       "      <td>10/01/2014</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10/01/2014 08:19:00 PM</td>\n",
       "      <td>10/01/2014</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>10/15/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3130355.0</td>\n",
       "      <td>3130355.0</td>\n",
       "      <td>30.315506</td>\n",
       "      <td>-97.690678</td>\n",
       "      <td>(30.31550566, -97.69067834)</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20115047788</td>\n",
       "      <td>RUNAWAY CHILD</td>\n",
       "      <td>4100</td>\n",
       "      <td>N</td>\n",
       "      <td>10/11/2011 06:00:00 AM</td>\n",
       "      <td>10/11/2011</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10/11/2011 10:49:00 AM</td>\n",
       "      <td>10/11/2011</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>10/12/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3137779.0</td>\n",
       "      <td>3137779.0</td>\n",
       "      <td>30.319818</td>\n",
       "      <td>-97.667024</td>\n",
       "      <td>(30.31981803, -97.66702419)</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20112011254</td>\n",
       "      <td>VIOL CITY ORDINANCE - OTHER</td>\n",
       "      <td>3299</td>\n",
       "      <td>N</td>\n",
       "      <td>07/20/2011 05:05:00 PM</td>\n",
       "      <td>07/20/2011</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>07/20/2011 05:05:00 PM</td>\n",
       "      <td>07/20/2011</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>09/03/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3106719.0</td>\n",
       "      <td>3106719.0</td>\n",
       "      <td>30.266295</td>\n",
       "      <td>-97.766915</td>\n",
       "      <td>(30.26629453, -97.76691542)</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20145045267</td>\n",
       "      <td>BURGLARY OF VEHICLE</td>\n",
       "      <td>601</td>\n",
       "      <td>N</td>\n",
       "      <td>10/11/2014 05:00:00 PM</td>\n",
       "      <td>10/11/2014</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>10/12/2014 04:13:00 AM</td>\n",
       "      <td>10/12/2014</td>\n",
       "      <td>413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>11/04/2014</td>\n",
       "      <td>23F</td>\n",
       "      <td>Theft</td>\n",
       "      <td>3115529.0</td>\n",
       "      <td>3115529.0</td>\n",
       "      <td>30.268006</td>\n",
       "      <td>-97.738955</td>\n",
       "      <td>(30.26800598, -97.73895531)</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013141039</td>\n",
       "      <td>AGG ROBBERY/DEADLY WEAPON</td>\n",
       "      <td>300</td>\n",
       "      <td>N</td>\n",
       "      <td>01/14/2013 03:16:00 PM</td>\n",
       "      <td>01/14/2013</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>01/14/2013 03:16:00 PM</td>\n",
       "      <td>01/14/2013</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>02/18/2013</td>\n",
       "      <td>120</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>3125085.0</td>\n",
       "      <td>3125085.0</td>\n",
       "      <td>30.314675</td>\n",
       "      <td>-97.707407</td>\n",
       "      <td>(30.31467502, -97.70740742)</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    inc_number                high_off_desc  high_off_code fam_viol  \\\n",
       "0  20145043640     VIOL OF PROTECTIVE ORDER           3009        N   \n",
       "1  20115047788                RUNAWAY CHILD           4100        N   \n",
       "3  20112011254  VIOL CITY ORDINANCE - OTHER           3299        N   \n",
       "6  20145045267          BURGLARY OF VEHICLE            601        N   \n",
       "7   2013141039    AGG ROBBERY/DEADLY WEAPON            300        N   \n",
       "\n",
       "                date_time        date    time        report_date_time  \\\n",
       "0  10/01/2014 08:19:00 PM  10/01/2014  2019.0  10/01/2014 08:19:00 PM   \n",
       "1  10/11/2011 06:00:00 AM  10/11/2011   600.0  10/11/2011 10:49:00 AM   \n",
       "3  07/20/2011 05:05:00 PM  07/20/2011  1705.0  07/20/2011 05:05:00 PM   \n",
       "6  10/11/2014 05:00:00 PM  10/11/2014  1700.0  10/12/2014 04:13:00 AM   \n",
       "7  01/14/2013 03:16:00 PM  01/14/2013  1516.0  01/14/2013 03:16:00 PM   \n",
       "\n",
       "  report_date  report_time  ...  clr_status    clr_date  ucr  cat_desc  \\\n",
       "0  10/01/2014       2019.0  ...           N  10/15/2014  NaN       NaN   \n",
       "1  10/11/2011       1049.0  ...           N  10/12/2011  NaN       NaN   \n",
       "3  07/20/2011       1705.0  ...           C  09/03/2011  NaN       NaN   \n",
       "6  10/12/2014        413.0  ...           N  11/04/2014  23F     Theft   \n",
       "7  01/14/2013       1516.0  ...           C  02/18/2013  120   Robbery   \n",
       "\n",
       "     x_coord    y_coord   latitude longtitude                     location  \\\n",
       "0  3130355.0  3130355.0  30.315506 -97.690678  (30.31550566, -97.69067834)   \n",
       "1  3137779.0  3137779.0  30.319818 -97.667024  (30.31981803, -97.66702419)   \n",
       "3  3106719.0  3106719.0  30.266295 -97.766915  (30.26629453, -97.76691542)   \n",
       "6  3115529.0  3115529.0  30.268006 -97.738955  (30.26800598, -97.73895531)   \n",
       "7  3125085.0  3125085.0  30.314675 -97.707407  (30.31467502, -97.70740742)   \n",
       "\n",
       "   year  \n",
       "0  2014  \n",
       "1  2011  \n",
       "3  2011  \n",
       "6  2014  \n",
       "7  2013  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(crimes2009_2016.shape)\n",
    "crimes2009_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the resistance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resistance_09 = pd.read_csv(\"https://data.austintexas.gov/api/views/sc8s-w4ka/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_10 = pd.read_csv(\"https://data.austintexas.gov/api/views/q5ym-htjz/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_11 = pd.read_csv(\"https://data.austintexas.gov/api/views/jipa-v8m5/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_12 = pd.read_csv(\"https://data.austintexas.gov/api/views/bx9w-y5sd/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_13 = pd.read_csv(\"https://data.austintexas.gov/api/views/qxx9-6iwk/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_14 = pd.read_csv(\"https://data.austintexas.gov/api/views/vv43-e55n/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_15 = pd.read_csv(\"https://data.austintexas.gov/api/views/iydp-s2cf/rows.csv?accessType=DOWNLOAD\").astype(str)\n",
    "resistance_16 = pd.read_csv(\"https://data.austintexas.gov/api/views/h8jq-pcz3/rows.csv?accessType=DOWNLOAD\").astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these datasets have different colnames - here, we standardize them so that we can combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_resistance = ['rin', 'prim_key', 'date', 'time', 'address', 'area_command', 'nature_of_contact', 'reason_desc', 'r2r_level', 'master_sub_id', 'sub_sex']\n",
    "columns2_resistance = ['sub_race', 'sub_ethn', 'sub_cond_desc', 'sub_res', 'weapon_1', 'weapon_2', 'weapon_3', 'weapon_4', 'weapon_5', 'num_shots', 'sub_eff', 'eff_on_officer']\n",
    "columns3_resistance = ['off_org_desc', 'off_comm_date', 'off_years_service', 'x_coord', 'y_coord', 'council_district']\n",
    "columns_resistance += columns2_resistance + columns3_resistance\n",
    "resistance_09.columns = columns_resistance\n",
    "resistance_10.columns = columns_resistance\n",
    "resistance_11.columns = columns_resistance\n",
    "resistance_12.columns = columns_resistance\n",
    "resistance_13.columns = columns_resistance\n",
    "resistance_14.columns = columns_resistance\n",
    "resistance_15.columns = columns_resistance\n",
    "resistance_16.columns = columns_resistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the data for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resistances = [resistance_09,resistance_10,resistance_11,resistance_12, resistance_13,resistance_14,resistance_15, resistance_16]\n",
    "resistance = pd.concat(resistances,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23218, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rin</th>\n",
       "      <th>prim_key</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>address</th>\n",
       "      <th>area_command</th>\n",
       "      <th>nature_of_contact</th>\n",
       "      <th>reason_desc</th>\n",
       "      <th>r2r_level</th>\n",
       "      <th>master_sub_id</th>\n",
       "      <th>...</th>\n",
       "      <th>weapon_5</th>\n",
       "      <th>num_shots</th>\n",
       "      <th>sub_eff</th>\n",
       "      <th>eff_on_officer</th>\n",
       "      <th>off_org_desc</th>\n",
       "      <th>off_comm_date</th>\n",
       "      <th>off_years_service</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>council_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19654</td>\n",
       "      <td>200910720</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td></td>\n",
       "      <td>200 W 4TH ST</td>\n",
       "      <td>GE</td>\n",
       "      <td>VIEWED OFFENSE</td>\n",
       "      <td>NECESSARY TO EFFECT ARREST / DETENTION</td>\n",
       "      <td>3.0</td>\n",
       "      <td>305859998: 200910720</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>GEORGE 400 REG I PATROL</td>\n",
       "      <td>01/08/1993 12:00:00 AM</td>\n",
       "      <td>16</td>\n",
       "      <td>3113640</td>\n",
       "      <td>10070272</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19656</td>\n",
       "      <td>200910883</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td>0330</td>\n",
       "      <td>6309 BURNS ST</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>NECESSARY TO DEFEND REPORTING OFFICER</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66128268: 200910883</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MINOR INJURY</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 700 REG I PATROL</td>\n",
       "      <td>04/27/2007 12:00:00 AM</td>\n",
       "      <td>2</td>\n",
       "      <td>3120652</td>\n",
       "      <td>10093724</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19734</td>\n",
       "      <td>200910883</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td></td>\n",
       "      <td>6309 BURNS ST</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>NECESSARY TO EFFECT ARREST / DETENTION</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66128268: 200910883</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MINOR INJURY</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 700 REG I PATROL</td>\n",
       "      <td>06/20/2008 12:00:00 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>3120652</td>\n",
       "      <td>10093724</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19735</td>\n",
       "      <td>200911936</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td>1640</td>\n",
       "      <td>6710 ARROYO SECO</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>OTHER (DOCUMENT IN SUPPLEMENT)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>219233449: 200911936</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 300 REG I PATROL</td>\n",
       "      <td>06/18/2004 12:00:00 AM</td>\n",
       "      <td>5</td>\n",
       "      <td>3117560</td>\n",
       "      <td>10097233</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19736</td>\n",
       "      <td>200911936</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "      <td>1635</td>\n",
       "      <td>6710 ARROYO SECO</td>\n",
       "      <td>ID</td>\n",
       "      <td>DISPATCHED CALL</td>\n",
       "      <td>OTHER (DOCUMENT IN SUPPLEMENT)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>314316133: 200911936</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>NO COMPLAINT OF INJURY/PAIN</td>\n",
       "      <td>BAKER 300 REG I PATROL</td>\n",
       "      <td>01/04/2008 12:00:00 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>3117560</td>\n",
       "      <td>10097233</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rin   prim_key                    date  time           address  \\\n",
       "0  19654  200910720  01/01/2009 12:00:00 AM            200 W 4TH ST   \n",
       "1  19656  200910883  01/01/2009 12:00:00 AM  0330     6309 BURNS ST   \n",
       "2  19734  200910883  01/01/2009 12:00:00 AM           6309 BURNS ST   \n",
       "3  19735  200911936  01/01/2009 12:00:00 AM  1640  6710 ARROYO SECO   \n",
       "4  19736  200911936  01/01/2009 12:00:00 AM  1635  6710 ARROYO SECO   \n",
       "\n",
       "  area_command nature_of_contact                             reason_desc  \\\n",
       "0           GE    VIEWED OFFENSE  NECESSARY TO EFFECT ARREST / DETENTION   \n",
       "1           ID   DISPATCHED CALL   NECESSARY TO DEFEND REPORTING OFFICER   \n",
       "2           ID   DISPATCHED CALL  NECESSARY TO EFFECT ARREST / DETENTION   \n",
       "3           ID   DISPATCHED CALL          OTHER (DOCUMENT IN SUPPLEMENT)   \n",
       "4           ID   DISPATCHED CALL          OTHER (DOCUMENT IN SUPPLEMENT)   \n",
       "\n",
       "  r2r_level         master_sub_id       ...        weapon_5 num_shots  \\\n",
       "0       3.0  305859998: 200910720       ...             nan       nan   \n",
       "1       2.0   66128268: 200910883       ...             nan       1.0   \n",
       "2       1.0   66128268: 200910883       ...             nan       0.0   \n",
       "3       3.0  219233449: 200911936       ...             nan       nan   \n",
       "4       3.0  314316133: 200911936       ...             nan       nan   \n",
       "\n",
       "                       sub_eff               eff_on_officer  \\\n",
       "0  NO COMPLAINT OF INJURY/PAIN  NO COMPLAINT OF INJURY/PAIN   \n",
       "1                 MINOR INJURY  NO COMPLAINT OF INJURY/PAIN   \n",
       "2                 MINOR INJURY  NO COMPLAINT OF INJURY/PAIN   \n",
       "3  NO COMPLAINT OF INJURY/PAIN  NO COMPLAINT OF INJURY/PAIN   \n",
       "4  NO COMPLAINT OF INJURY/PAIN  NO COMPLAINT OF INJURY/PAIN   \n",
       "\n",
       "              off_org_desc           off_comm_date off_years_service  x_coord  \\\n",
       "0  GEORGE 400 REG I PATROL  01/08/1993 12:00:00 AM                16  3113640   \n",
       "1   BAKER 700 REG I PATROL  04/27/2007 12:00:00 AM                 2  3120652   \n",
       "2   BAKER 700 REG I PATROL  06/20/2008 12:00:00 AM                 1  3120652   \n",
       "3   BAKER 300 REG I PATROL  06/18/2004 12:00:00 AM                 5  3117560   \n",
       "4   BAKER 300 REG I PATROL  01/04/2008 12:00:00 AM                 1  3117560   \n",
       "\n",
       "    y_coord council_district  \n",
       "0  10070272              9.0  \n",
       "1  10093724              4.0  \n",
       "2  10093724              4.0  \n",
       "3  10097233              7.0  \n",
       "4  10097233              7.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(resistance.shape)\n",
    "resistance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the resistance data with the crime data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resistance data, each primary key (\"prim_key\") represents an incident, and each record is a single officer's report of that incident. This means that there are often multiple records per primary key. In order to merge one-to-one, we want only one record per primary key.\n",
    "\n",
    "First, we should determine which columns are at the report level and which are at the primary key level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 5626\n",
      "nature_of_contact 828\n",
      "reason_desc 2100\n",
      "r2r_level 685\n",
      "master_sub_id 1451\n",
      "sub_sex 461\n",
      "sub_race 406\n",
      "sub_ethn 460\n",
      "sub_cond_desc 1120\n",
      "sub_res 2910\n",
      "weapon_1 1989\n",
      "weapon_2 729\n",
      "weapon_3 110\n",
      "weapon_4 9\n",
      "weapon_5 1\n",
      "num_shots 1814\n",
      "sub_eff 2194\n",
      "eff_on_officer 1722\n",
      "off_org_desc 3419\n",
      "off_comm_date 8258\n",
      "off_years_service 7599\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique primary keys\n",
    "n_prim_key = len(resistance[\"prim_key\"].unique())\n",
    "\n",
    "# For each other column in the resistence dataset, check if the number of unique records in terms of the primary key i\n",
    "for col in resistance.columns[3:]:\n",
    "    n_col = len(resistance.groupby([\"prim_key\", col]))\n",
    "    if n_col != n_prim_key:\n",
    "        diff = n_col-n_prim_key\n",
    "        print(col, diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few of these variables that we might want to use as dependent variables, so we will clean them so that there is one value per primary key as follows:\n",
    "1. weapon_* --> a dummy marking whether any officer reported a weapon\n",
    "2. r2r_level -->  most severe r2r level (lower numbers = more severe resistance) reported by any officer\n",
    "3. number_of_shots --> dummy marking whether any officer reported a shot fired\n",
    "4. sub_eff --> whether any officer reported that a subject complained of pain/injury\n",
    "5. eff_on_officer --> whether any officer complained of pain/injury\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean weapon variables\n",
    "resistance[\"weapon\"] = 0\n",
    "for col in [\"weapon_1\", \"weapon_2\", \"weapon_3\", \"weapon_4\", \"weapon_5\"]:\n",
    "    resistance.loc[~resistance[col].isin([\"WEAPONLESS (PRESSURE POINTS/KICKS/HAND)\", \"-\", \"nan\"]), \"weapon\"] = 1 \n",
    "    # Note: nan is usually used to mark weapons 2-5, I think we can safely assume that it means no weapon\n",
    "# Show that we've correctly marked cases where any weapon was used\n",
    "#resistance[[\"weapon_1\", \"weapon_2\", \"weapon_3\", \"weapon_4\", \"weapon_5\", \"weapon\"]].head(20)\n",
    "#resistance.weapon.value_counts()\n",
    "# Mark the entire primary key as having a weapon used if any police officer reported it as such\n",
    "resistance[\"any_weapon\"] = resistance.groupby(['prim_key'])['weapon'].transform(max)\n",
    "\n",
    "# Clean r2r level \n",
    "resistance['r2r_level'] = resistance['r2r_level'].astype(float)\n",
    "resistance[\"max_r2r\"] = resistance.groupby(['prim_key'])['r2r_level'].transform(min) # Note: lower numbers = more severe resistance\n",
    "\n",
    "# Clean number of shots\n",
    "resistance[\"shot\"] = 0\n",
    "resistance.loc[resistance[\"num_shots\"]!=\"nan\", \"shot\"] = 1\n",
    "resistance[\"any_shot\"] = resistance.groupby(['prim_key'])['shot'].transform(max)\n",
    "\n",
    "# Clean subject complaint of pain/njury\n",
    "resistance[\"sub_complaint\"] = 0\n",
    "resistance.loc[~resistance[\"sub_eff\"].isin([\"NO COMPLAINT OF INJURY/PAIN\"]), \"weapon\"] = 1\n",
    "resistance[\"any_sub_complaint\"] = resistance.groupby(['prim_key'])['sub_complaint'].transform(max)\n",
    "\n",
    "# Clean officer complaint of pain/njury\n",
    "resistance[\"off_complaint\"] = 0\n",
    "resistance.loc[~resistance[\"eff_on_officer\"].isin([\"NO COMPLAINT OF INJURY/PAIN\"]), \"weapon\"] = 1\n",
    "resistance[\"any_off_complaint\"] = resistance.groupby(['prim_key'])['off_complaint'].transform(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the columns of resistance that we want to use, and drop duplicates so that there is one observation per primary key instead of one obsercation per report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Keep only necessary columns\n",
    "resistance = resistance[[\"prim_key\", \"date\", \"address\",\n",
    "                         \"any_weapon\", \"max_r2r\", \"any_shot\", \"any_sub_complaint\", \"any_off_complaint\"]]\n",
    "\n",
    "# Drop duplicates\n",
    "resistance = resistance.drop_duplicates()\n",
    "\n",
    "# Confirm data is now unique by primary key\n",
    "print(len(resistance[\"prim_key\"].unique()) == resistance.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"prim_key\" in the resistance data appears similar to \"inc_number\" in the crime data, but sometimes these have different numbers of characters. However, by looking closely at one year of data, we found that the addresses do tend to match exactly for cases that have similar \"prim_key\" and \"inc_number\" values that are slightly different lengths. \n",
    "\n",
    "We therefore take the first six characters of \"inc_number\" and \"prim_key\", and merge on these values PLUS the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_only     1036769\n",
       "both            13413\n",
       "right_only       1609\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimes2009_2016[\"inc_number\"] = crimes2009_2016[\"inc_number\"].apply(str)\n",
    "crimes2009_2016[\"prim_key_short\"] = crimes2009_2016[\"inc_number\"].str[0:7]\n",
    "resistance[\"prim_key_short\"] = resistance[\"prim_key\"].str[0:7]\n",
    "combined = pd.merge(crimes2009_2016, resistance, how=\"outer\", on=[\"prim_key_short\", \"address\"], indicator=True)\n",
    "combined._merge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect there to be a lot of \"left_only\" cases in the crime data that are not in the resistance data - these are all the cases where there was a crime but no resistance. \n",
    "\n",
    "However, we should be concerned about \"right_only\" cases where there was resistence to a crime, but that crime was not recorded in the full dataset. There are about 1,603 of these cases (and 13,420 merged correctly)\n",
    "\n",
    "Below, we look at some cases that didn't merge correctly and then drop them so that we can run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prim_key</th>\n",
       "      <th>date_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1050182</th>\n",
       "      <td>200910463</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050183</th>\n",
       "      <td>200911145</td>\n",
       "      <td>01/01/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050184</th>\n",
       "      <td>200920816</td>\n",
       "      <td>01/02/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050185</th>\n",
       "      <td>200971637</td>\n",
       "      <td>01/07/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050186</th>\n",
       "      <td>200982170</td>\n",
       "      <td>01/08/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050187</th>\n",
       "      <td>2009190995</td>\n",
       "      <td>01/19/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050188</th>\n",
       "      <td>2009312306</td>\n",
       "      <td>01/31/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050189</th>\n",
       "      <td>2009372629</td>\n",
       "      <td>02/06/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050190</th>\n",
       "      <td>2009391534</td>\n",
       "      <td>02/08/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050191</th>\n",
       "      <td>2009390389</td>\n",
       "      <td>02/08/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050192</th>\n",
       "      <td>2009421662</td>\n",
       "      <td>02/11/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050193</th>\n",
       "      <td>2009452060</td>\n",
       "      <td>02/14/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050194</th>\n",
       "      <td>2009531645</td>\n",
       "      <td>02/22/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050195</th>\n",
       "      <td>2009561953</td>\n",
       "      <td>02/25/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050196</th>\n",
       "      <td>2009582841</td>\n",
       "      <td>02/27/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050197</th>\n",
       "      <td>2009592575</td>\n",
       "      <td>02/28/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050198</th>\n",
       "      <td>2009691364</td>\n",
       "      <td>03/10/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050199</th>\n",
       "      <td>2009702078</td>\n",
       "      <td>03/12/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050200</th>\n",
       "      <td>2009771906</td>\n",
       "      <td>03/18/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050201</th>\n",
       "      <td>2009820656</td>\n",
       "      <td>03/23/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050202</th>\n",
       "      <td>2009820767</td>\n",
       "      <td>03/23/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050203</th>\n",
       "      <td>2009872281</td>\n",
       "      <td>03/28/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050204</th>\n",
       "      <td>2009901534</td>\n",
       "      <td>03/31/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050205</th>\n",
       "      <td>2009900157</td>\n",
       "      <td>03/31/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050206</th>\n",
       "      <td>2009950825</td>\n",
       "      <td>04/05/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050207</th>\n",
       "      <td>2009971806</td>\n",
       "      <td>04/07/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050208</th>\n",
       "      <td>2009981186</td>\n",
       "      <td>04/08/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050209</th>\n",
       "      <td>20091002356</td>\n",
       "      <td>04/10/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050210</th>\n",
       "      <td>20091040232</td>\n",
       "      <td>04/14/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050211</th>\n",
       "      <td>20091111916</td>\n",
       "      <td>04/21/2009 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051761</th>\n",
       "      <td>20162550847</td>\n",
       "      <td>09/11/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051762</th>\n",
       "      <td>20162740750</td>\n",
       "      <td>09/30/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051763</th>\n",
       "      <td>20161811700</td>\n",
       "      <td>06/29/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051764</th>\n",
       "      <td>20163431446</td>\n",
       "      <td>12/08/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051765</th>\n",
       "      <td>20163201312</td>\n",
       "      <td>11/15/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051766</th>\n",
       "      <td>201610642</td>\n",
       "      <td>01/01/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051767</th>\n",
       "      <td>2016351376</td>\n",
       "      <td>02/04/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051768</th>\n",
       "      <td>2016271568</td>\n",
       "      <td>01/27/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051769</th>\n",
       "      <td>2016380420</td>\n",
       "      <td>02/07/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051770</th>\n",
       "      <td>2016610635</td>\n",
       "      <td>03/01/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051771</th>\n",
       "      <td>2016621810</td>\n",
       "      <td>03/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051772</th>\n",
       "      <td>20161100124</td>\n",
       "      <td>04/19/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051773</th>\n",
       "      <td>20161140621</td>\n",
       "      <td>04/23/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051774</th>\n",
       "      <td>20161161717</td>\n",
       "      <td>04/25/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051775</th>\n",
       "      <td>20161431723</td>\n",
       "      <td>05/22/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051776</th>\n",
       "      <td>20161540371</td>\n",
       "      <td>06/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051777</th>\n",
       "      <td>20162300722</td>\n",
       "      <td>08/17/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051778</th>\n",
       "      <td>20162360045</td>\n",
       "      <td>08/23/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051779</th>\n",
       "      <td>20162680219</td>\n",
       "      <td>09/24/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051780</th>\n",
       "      <td>20162820329</td>\n",
       "      <td>10/08/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051781</th>\n",
       "      <td>20162880773</td>\n",
       "      <td>10/14/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051782</th>\n",
       "      <td>20163030595</td>\n",
       "      <td>10/29/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051783</th>\n",
       "      <td>20163440043</td>\n",
       "      <td>12/09/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051784</th>\n",
       "      <td>20161250001</td>\n",
       "      <td>05/04/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051785</th>\n",
       "      <td>20161961222</td>\n",
       "      <td>07/14/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051786</th>\n",
       "      <td>20162170221</td>\n",
       "      <td>08/04/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051787</th>\n",
       "      <td>20163190105</td>\n",
       "      <td>11/14/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051788</th>\n",
       "      <td>20161360492</td>\n",
       "      <td>05/15/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051789</th>\n",
       "      <td>20162791102</td>\n",
       "      <td>10/05/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051790</th>\n",
       "      <td>20163541112</td>\n",
       "      <td>12/19/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prim_key                  date_y\n",
       "1050182    200910463  01/01/2009 12:00:00 AM\n",
       "1050183    200911145  01/01/2009 12:00:00 AM\n",
       "1050184    200920816  01/02/2009 12:00:00 AM\n",
       "1050185    200971637  01/07/2009 12:00:00 AM\n",
       "1050186    200982170  01/08/2009 12:00:00 AM\n",
       "1050187   2009190995  01/19/2009 12:00:00 AM\n",
       "1050188   2009312306  01/31/2009 12:00:00 AM\n",
       "1050189   2009372629  02/06/2009 12:00:00 AM\n",
       "1050190   2009391534  02/08/2009 12:00:00 AM\n",
       "1050191   2009390389  02/08/2009 12:00:00 AM\n",
       "1050192   2009421662  02/11/2009 12:00:00 AM\n",
       "1050193   2009452060  02/14/2009 12:00:00 AM\n",
       "1050194   2009531645  02/22/2009 12:00:00 AM\n",
       "1050195   2009561953  02/25/2009 12:00:00 AM\n",
       "1050196   2009582841  02/27/2009 12:00:00 AM\n",
       "1050197   2009592575  02/28/2009 12:00:00 AM\n",
       "1050198   2009691364  03/10/2009 12:00:00 AM\n",
       "1050199   2009702078  03/12/2009 12:00:00 AM\n",
       "1050200   2009771906  03/18/2009 12:00:00 AM\n",
       "1050201   2009820656  03/23/2009 12:00:00 AM\n",
       "1050202   2009820767  03/23/2009 12:00:00 AM\n",
       "1050203   2009872281  03/28/2009 12:00:00 AM\n",
       "1050204   2009901534  03/31/2009 12:00:00 AM\n",
       "1050205   2009900157  03/31/2009 12:00:00 AM\n",
       "1050206   2009950825  04/05/2009 12:00:00 AM\n",
       "1050207   2009971806  04/07/2009 12:00:00 AM\n",
       "1050208   2009981186  04/08/2009 12:00:00 AM\n",
       "1050209  20091002356  04/10/2009 12:00:00 AM\n",
       "1050210  20091040232  04/14/2009 12:00:00 AM\n",
       "1050211  20091111916  04/21/2009 12:00:00 AM\n",
       "...              ...                     ...\n",
       "1051761  20162550847              09/11/2016\n",
       "1051762  20162740750              09/30/2016\n",
       "1051763  20161811700              06/29/2016\n",
       "1051764  20163431446              12/08/2016\n",
       "1051765  20163201312              11/15/2016\n",
       "1051766    201610642              01/01/2016\n",
       "1051767   2016351376              02/04/2016\n",
       "1051768   2016271568              01/27/2016\n",
       "1051769   2016380420              02/07/2016\n",
       "1051770   2016610635              03/01/2016\n",
       "1051771   2016621810              03/02/2016\n",
       "1051772  20161100124              04/19/2016\n",
       "1051773  20161140621              04/23/2016\n",
       "1051774  20161161717              04/25/2016\n",
       "1051775  20161431723              05/22/2016\n",
       "1051776  20161540371              06/02/2016\n",
       "1051777  20162300722              08/17/2016\n",
       "1051778  20162360045              08/23/2016\n",
       "1051779  20162680219              09/24/2016\n",
       "1051780  20162820329              10/08/2016\n",
       "1051781  20162880773              10/14/2016\n",
       "1051782  20163030595              10/29/2016\n",
       "1051783  20163440043              12/09/2016\n",
       "1051784  20161250001              05/04/2016\n",
       "1051785  20161961222              07/14/2016\n",
       "1051786  20162170221              08/04/2016\n",
       "1051787  20163190105              11/14/2016\n",
       "1051788  20161360492              05/15/2016\n",
       "1051789  20162791102              10/05/2016\n",
       "1051790  20163541112              12/19/2016\n",
       "\n",
       "[1609 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.loc[combined._merge == \"right_only\", [\"prim_key\", \"date_y\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.loc[combined._merge != \"right_only\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll create a dummy marking the cases that were in the resistance data has having had some sort of resistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1036769\n",
       "1      13413\n",
       "Name: any_resistance, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"any_resistance\"] = 0\n",
    "combined.loc[combined._merge == \"both\", \"any_resistance\"] = 1\n",
    "combined.drop(\"_merge\", axis=1, inplace=True)\n",
    "combined.any_resistance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the outcome variables\n",
    "\n",
    "We use two target variables - one measuring whether there was any resistance and one measuring whether there was any resistance where anyone (officer or subject) complained of pain/injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking types\n",
    "combined.dtypes\n",
    "\n",
    "#replacing NaN with zero\n",
    "outcome = ['any_weapon','max_r2r','any_shot','any_sub_complaint','any_off_complaint']\n",
    "combined[outcome] = combined[outcome].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE: I don't think the code below for Target 2 does what we discussed? I think it will always equal 1 if any_resistance is 1 since it takes the max. Can someone explain it to me on Tuesday?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create target variables\n",
    "combined['Target1'] = combined['any_resistance']\n",
    "\n",
    "target2 = []\n",
    "for index, row in combined.iterrows():\n",
    "    target2.append(max(row['any_resistance'],max(row['any_sub_complaint'],row['any_off_complaint'])))\n",
    "combined['Target2'] = pd.DataFrame(target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1036769\n",
       "1.0      13413\n",
       "Name: Target2, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.Target2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare features based on when an incident occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in US Holiday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the US holidays from csv; data set is from 1966-2020\n",
    "us_holidays = pd.read_csv('Input Data/usholidays.csv')\n",
    "\n",
    "#creating a new column for each holiday that will show True or False for each day if it falls on that holiday\n",
    "us_holidays['new_year'] = us_holidays['Holiday'] == \"New Year's Day\"\n",
    "us_holidays['mlk_day'] = us_holidays['Holiday'] == \"Birthday of Martin Luther King, Jr.\"\n",
    "us_holidays['wash_bday'] = us_holidays['Holiday'] == \"Washington's Birthday\"\n",
    "us_holidays['mem_day'] = us_holidays['Holiday'] == \"Memorial Day\"\n",
    "us_holidays['ind_day'] = us_holidays['Holiday'] == \"Independence Day\"\n",
    "us_holidays['labor_day'] = us_holidays['Holiday'] == \"Labor Day\"\n",
    "us_holidays['col_day'] = us_holidays['Holiday'] == \"Columbus Day\"\n",
    "us_holidays['vet_day'] = us_holidays['Holiday'] == \"Veterans Day\"\n",
    "us_holidays['thanksgiving'] = us_holidays['Holiday'] == \"Thanksgiving Day\"\n",
    "us_holidays['christmas'] = us_holidays['Holiday'] == \"Christmas Day\"\n",
    "\n",
    "#re-format date from 'us_holidays' to match the 'combined' DataFrame's date format\n",
    "us_holidays['Date']= us_holidays['Date'].str.replace('-', '/', regex=False)\n",
    "\n",
    "#join the 'combined' and 'us_holidays' data frames on the date (date_x in 'combined', 'Date' in 'us_holidays')\n",
    "#rename new dataframe as 'combined2'\n",
    "combined2 = combined.join(us_holidays.set_index('Date'), on='date_x')\n",
    "\n",
    "#drop the unnecessary columns from the combined2 DataFrame (imported during join)\n",
    "combined2.drop(['Unnamed: 0', 'Holiday'], axis = 1)\n",
    "\n",
    "#to 'fill' the combined 2 DataFrame, use slicing to select the columns from 'us_holidays' that need to be filled\n",
    "#fill combined2 DataFrame with 'False'\n",
    "#Essentially, we're saying that any day that doesn't match a US holiday should say 'False' in that columm\n",
    "j = list(us_holidays.columns)[3:]\n",
    "combined2[j] = combined2[j].fillna(value= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features based on date and time of the incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inc_number                  object\n",
       "high_off_desc               object\n",
       "high_off_code              float64\n",
       "fam_viol                    object\n",
       "date_time           datetime64[ns]\n",
       "date_x                      object\n",
       "time                       float64\n",
       "report_date_time            object\n",
       "report_date                 object\n",
       "report_time                float64\n",
       "loc_t ype                   object\n",
       "address                     object\n",
       "zip_code                   float64\n",
       "council_district           float64\n",
       "apd_sector                  object\n",
       "apd_district                object\n",
       "pra                         object\n",
       "clr_status                  object\n",
       "clr_date                    object\n",
       "ucr                         object\n",
       "cat_desc                    object\n",
       "x_coord                    float64\n",
       "y_coord                    float64\n",
       "latitude                   float64\n",
       "longtitude                 float64\n",
       "location                    object\n",
       "year                        object\n",
       "prim_key_short              object\n",
       "prim_key                    object\n",
       "date_y                      object\n",
       "                         ...      \n",
       "P0030007                   float64\n",
       "P0030008                   float64\n",
       "P0130001                   float64\n",
       "P0130002                   float64\n",
       "P0130003                   float64\n",
       "P0180001                   float64\n",
       "P0200002                   float64\n",
       "P0250002                   float64\n",
       "P0190007                   float64\n",
       "has_census_data             object\n",
       "P0030002_pct               float64\n",
       "P0030003_pct               float64\n",
       "P0030004_pct               float64\n",
       "P0030005_pct               float64\n",
       "P0030006_pct               float64\n",
       "P0030007_pct               float64\n",
       "P0030008_pct               float64\n",
       "P0130001_pct               float64\n",
       "P0130002_pct               float64\n",
       "P0130003_pct               float64\n",
       "P0200002_pct               float64\n",
       "P0250002_pct               float64\n",
       "P0190007_pct               float64\n",
       "B01001_001E                float64\n",
       "B19113_001E                float64\n",
       "B17001_001E                float64\n",
       "C18120_002E                float64\n",
       "C18120_003E                float64\n",
       "B17001_001E_pct            float64\n",
       "C18120_003E_pct            float64\n",
       "Length: 73, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing to date format\n",
    "combined['date_time'] = combined['date_time'].astype('datetime64[ns]')\n",
    "#combined['report_date_time'] = combined['report_date_time'].astype('datetime64[ns]') # Arushi - I commented this out because it was taking forever to run on my computer\n",
    "#combined.dtypes\n",
    "\n",
    "#this should be used for time of day type calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in census data\n",
    "\n",
    "Census tract code for the two counties we care about should be six digits of the format 0ABCDE in order to merge with data from the Census API. We appear to have been something like the form BC.D, with leading/trailing zeroes dropped. Below, we clean the census tract data we were given to match the 0ABCDE format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \n",
    "ct_split = combined[\"cen_tract\"].str.split(\".\", expand=True)\n",
    "combined[\"ct1\"] = ct_split[0]\n",
    "combined[\"ct2\"] = ct_split[1]\n",
    "\n",
    "# Calculate the length of each split piece - if the first is <4 digits, we add leading zeros, and if the second is <2 digits, we add trailing zeroes\n",
    "combined[\"ct1_len\"] = combined.ct1.str.len()\n",
    "combined[\"ct2_len\"] = combined.ct2.str.len()\n",
    "combined.loc[combined.ct2_len==1, \"ct2\"] = combined.loc[combined.ct2_len==1, \"ct2\"] + \"0\"\n",
    "combined.loc[combined.ct2_len.isnull() & (combined.ct1_len <=4), \"ct2\"] = \"00\"\n",
    "combined.loc[combined.ct1_len==1, \"ct1\"] = \"000\" + combined.loc[combined.ct1_len==1, \"ct1\"] \n",
    "combined.loc[combined.ct1_len==2, \"ct1\"] = \"00\" + combined.loc[combined.ct1_len==2, \"ct1\"] \n",
    "combined.loc[combined.ct1_len==3, \"ct1\"] = \"0\" + combined.loc[combined.ct1_len==3, \"ct1\"] \n",
    "\n",
    "combined[\"ct1_len\"] = combined.ct1.str.len()\n",
    "combined[\"ct2_len\"] = combined.ct2.str.len()\n",
    "\n",
    "# Examine cases where either piece is > 2 digits - should not be possible\n",
    "combined.loc[combined.ct1_len >4, \"cen_tract\"].value_counts()\n",
    "# These look like they're missing a decimal point. I'm just going to assume the last two characters go after the decimal point.\n",
    "# (It's only 11 cases anyway.)\n",
    "combined.loc[combined.ct1_len >4, \"ct1\"] = combined.loc[combined.ct1_len >4, \"cen_tract\"][:-2]\n",
    "combined.loc[combined.ct1_len >4, \"ct2\"] = combined.loc[combined.ct1_len >4, \"cen_tract\"][-2:]\n",
    "\n",
    "# Concatenate the two parts\n",
    "combined[\"tract\"] = combined.ct1 + combined.ct2\n",
    "\n",
    "combined.drop([\"cen_tract\",\"ct1\", \"ct1_len\", \"ct2\", \"ct2_len\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll pull some relevant indicators from the 2010 Census API. See full documentation of Table SF1 codes here: https://www.census.gov/prod/cen2010/doc/sf1.pdf.\n",
    "The indicators we are pulling are:\n",
    "- P0030001 - total population (which we will need for the denominator)\n",
    "- P0030002 - white population\n",
    "- P0030003 - black population\n",
    "- P0030004 - American Indian/native Alaskan population\n",
    "- P0030005 - Asian population \n",
    "- P0030006 - Hawaiian / Pacific Islander population\n",
    "- P0030007 - other race population\n",
    "- P0030008 - 2+ races population\n",
    "- P0040003 - Hispanic or Latino population (NOTE: not a race)\n",
    "- P0130001 - median age\n",
    "- P0130002 - median age for males\n",
    "- P0130003 - median age for females\n",
    "- P0180001 - total households (which we will need for the denominator)\n",
    "- P0200002 - households with any children under 18\n",
    "- P0250002 - households with any member over 65\n",
    "- P0190007 - households with husband-wife\n",
    "\n",
    "There are about 5723 cases that were missing census tract data in the original file. These (of course) did not merge with the census data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"key\": \"7530e2501288a8dfb28803342f5d1493cf00cb96\",\n",
    "          \"state\": \"48\",   # Texas\n",
    "          \"county\": \"453,491\",  # Travis County, Williamson County\n",
    "          \"indicators\": \"P0030001,P0030002,P0030003,P0030004,P0030005,P0030006,P0030007,P0030008,P0130001,P0130002,P0130003,P0180001,P0200002,P0250002,P0190007\"\n",
    "         }\n",
    "url = \"https://api.census.gov/data/2010/sf1?get=\"+params[\"indicators\"]+\"&for=tract:*&in=state:\"+params[\"state\"]+\"&in=county:\"+params[\"county\"]+\"&key=\"+params[\"key\"]\n",
    "response = requests.get(url, data = {'key':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.DataFrame(response.json()[1:])\n",
    "census_data.columns = response.json()[0]\n",
    "census_data.drop([\"state\", \"county\"], axis=1, inplace=True)\n",
    "combined = pd.merge(combined, census_data, how=\"outer\", on=\"tract\", indicator=True)\n",
    "combined._merge.value_counts()\n",
    "combined = combined.loc[combined._merge != \"right_only\", ]\n",
    "combined[\"has_census_data\"] = combined._merge == \"both\"\n",
    "combined.drop(\"_merge\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will calculate each indicator as percent of total population / percent of households."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"P0030001\",\"P0030002\",\"P0030003\",\"P0030004\",\"P0030005\",\"P0030006\",\"P0030007\",\"P0030008\",\"P0130001\",\"P0130002\",\"P0130003\", \"P0180001\",\"P0200002\",\"P0250002\",\"P0190007\"]:\n",
    "    combined[col] = combined[col].astype(float)\n",
    "    \n",
    "for col in [\"P0030002\",\"P0030003\",\"P0030004\",\"P0030005\",\"P0030006\",\"P0030007\",\"P0030008\",\"P0130001\",\"P0130002\",\"P0130003\"]:\n",
    "    combined[col+\"_pct\"] = combined[col]/combined[\"P0030001\"]\n",
    "\n",
    "for col in [\"P0200002\",\"P0250002\",\"P0190007\"]:\n",
    "    combined[col+\"_pct\"] = combined[col]/combined[\"P0180001\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will also pull some data from the American Community Survey (ACS) 5-year estimates. We need to use the 5-year estimates in order to have data down to the tract level. The full list of available variables is here: https://api.census.gov/data/2016/acs/acs5/variables.html. The indicators we're using are:\n",
    "- B19113_001E - median family income in the past 12 months\n",
    "- B01001_001E - total population (which we will need for the denominator)\n",
    "- B17001_001E - poverty status in the past 12 months \n",
    "- C18120_002e - total labor force (which we will need for the denominator)\n",
    "- C18120_003E - total employed in the labor force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"key\": \"7530e2501288a8dfb28803342f5d1493cf00cb96\",\n",
    "          \"state\": \"48\",   # Texas\n",
    "          \"county\": \"453,491\",  # Travis County, Williamson County\n",
    "          \"indicators\": \"B01001_001E,B19113_001E,B17001_001E,C18120_002E,C18120_003E\"\n",
    "         }\n",
    "url = \"https://api.census.gov/data/2016/acs/acs5?get=\"+params[\"indicators\"]+\"&for=tract:*&in=state:\"+params[\"state\"]+\"&in=county:\"+params[\"county\"]+\"&key=\"+params[\"key\"]\n",
    "response = requests.get(url, data = {'key':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_data = pd.DataFrame(response.json()[1:])\n",
    "acs_data.columns = response.json()[0]\n",
    "acs_data.drop([\"state\", \"county\"], axis=1, inplace=True)\n",
    "for col in ['B01001_001E','B19113_001E','B17001_001E','C18120_002E','C18120_003E']:\n",
    "    acs_data[col] = acs_data[col].astype(float)\n",
    "#Missing values are recorded as -666666666; must clean these.\n",
    "acs_data.B19113_001E.replace(-666666666, None, inplace=True)\n",
    "combined = pd.merge(combined, acs_data, how=\"outer\", on=\"tract\", indicator=True)\n",
    "combined._merge.value_counts()\n",
    "combined = combined.loc[combined._merge != \"right_only\", ]\n",
    "combined.drop(\"_merge\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will calculate each indicator as percent of the relevant population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"B17001_001E_pct\"] = combined.B17001_001E/combined.B01001_001E\n",
    "combined[\"C18120_003E_pct\"] = combined.C18120_003E/combined.C18120_002E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
